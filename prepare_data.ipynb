{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize\n",
    "import string\n",
    "import h5py\n",
    "import matplotlib\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pixel_depth = 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://ufldl.stanford.edu/housenumbers/'\n",
    "last_percent_reported = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "    global last_percent_reported\n",
    "    percent = int(count * blockSize * 100 / totalSize)\n",
    "    \n",
    "    if last_percent_reported != percent:\n",
    "        if percent % 5 == 0:\n",
    "            sys.stdout.write(\"%s%%\" % percent)\n",
    "            sys.stdout.flush()\n",
    "        else:\n",
    "            sys.stdout.write(\".\")\n",
    "            sys.stdout.flush()\n",
    "                \n",
    "        last_percent_reported = percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maybe_download(filename, expected_bytes, force=False):\n",
    "    if force or not os.path.exists(filename):\n",
    "        print('Attempting to download:', filename) \n",
    "        filename, _ = urlretrieve(url + filename, filename, reporthook=download_progress_hook)\n",
    "        print('\\nDownload Complete!')\n",
    "    statinfo = os.stat(filename)\n",
    "    if statinfo.st_size == expected_bytes:\n",
    "        print('Found and verified', filename)\n",
    "    else:\n",
    "        raise Exception(\n",
    "            'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "        return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified train.tar.gz\n",
      "Found and verified test.tar.gz\n"
     ]
    }
   ],
   "source": [
    "maybe_download('train.tar.gz', 404141560)\n",
    "maybe_download('test.tar.gz', 276555967)\n",
    "\n",
    "train_filename = 'train.tar.gz'\n",
    "test_filename = 'test.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maybe_extract(filename, force=False):\n",
    "    root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "    if os.path.isdir(root) and not force:\n",
    "        # You may override by setting force=True\n",
    "        print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "    else:\n",
    "        print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "        tar = tarfile.open(filename)\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "    data_folders = [\n",
    "        os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "        if os.path.isdir(os.path.join(root, d))]\n",
    "    return data_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train already present - Skipping extraction of train.tar.gz.\n",
      "test already present - Skipping extraction of test.tar.gz.\n"
     ]
    }
   ],
   "source": [
    "train_folders = maybe_extract(train_filename)\n",
    "test_folders = maybe_extract(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_attr (f, i, name):\n",
    "    attr = f[f['digitStruct']['bbox'][i][0]][name].value.squeeze()\n",
    "    \n",
    "    if attr.dtype == 'float64':\n",
    "        return attr.reshape(-1)\n",
    "    \n",
    "    return np.array([f[x].value for x in attr]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label (f, i):\n",
    "    label = f[f['digitStruct']['name'][i][0]].value.tostring()\n",
    "    return label.replace('\\x00', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data (path):\n",
    "    f = h5py.File(path)\n",
    "    \n",
    "    images = np.ndarray(shape = (f['digitStruct']['name'].shape[0],), dtype = '|S15')\n",
    "    labels = np.zeros((len(f['digitStruct']['bbox']), 6), dtype = 'float')\n",
    "    tops = np.zeros((len(f['digitStruct']['bbox']), 6), dtype = 'float')\n",
    "    heights = np.zeros((len(f['digitStruct']['bbox']), 6), dtype = 'float')\n",
    "    widths = np.zeros((len(f['digitStruct']['bbox']), 6), dtype = 'float')\n",
    "    lefts = np.zeros((len(f['digitStruct']['bbox']), 6), dtype = 'float')\n",
    "    labels.fill(10)\n",
    "    \n",
    "    for i in xrange(f['digitStruct']['name'].shape[0]):\n",
    "        images[i] = get_label(f, i)\n",
    "        \n",
    "        label_attr = get_attr(f, i, 'label')\n",
    "        top_attr = get_attr(f, i, 'top')\n",
    "        height_attr = get_attr(f, i , 'height')\n",
    "        width_attr = get_attr(f, i, 'width')\n",
    "        left_attr = get_attr(f, i , 'left')\n",
    "        \n",
    "        labels[i, :label_attr.shape[0]] = label_attr\n",
    "        tops[i, :top_attr.shape[0]] = top_attr\n",
    "        heights[i, :height_attr.shape[0]] = height_attr\n",
    "        widths[i, :width_attr.shape[0]] = width_attr\n",
    "        lefts[i, :left_attr.shape[0]] = left_attr\n",
    "        \n",
    "        if (i % 5000 == 0):\n",
    "            print (i, 'passed')\n",
    "        \n",
    "    return labels, images, tops, heights, widths, lefts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 passed\n",
      "5000 passed\n",
      "10000 passed\n",
      "15000 passed\n",
      "20000 passed\n",
      "25000 passed\n",
      "30000 passed\n",
      "0 passed\n",
      "5000 passed\n",
      "10000 passed\n"
     ]
    }
   ],
   "source": [
    "train_tuple = load_data('train/digitStruct.mat')\n",
    "test_tuple = load_data('test/digitStruct.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maybe_pickle (struct, force=False):\n",
    "    if os.path.exists(struct + '.pickle') and not force:\n",
    "        print('file already present, skipping')\n",
    "    else:\n",
    "        print('pickling file')\n",
    "        \n",
    "        dataset = {\n",
    "            'train': {\n",
    "                'labels': train_tuple[0],\n",
    "                'images': train_tuple[1],\n",
    "                'tops': train_tuple[2],\n",
    "                'heights': train_tuple[3],\n",
    "                'widths': train_tuple[4],\n",
    "                'lefts': train_tuple[5]\n",
    "            },\n",
    "            'test': {\n",
    "                'labels': test_tuple[0],\n",
    "                'images': test_tuple[1],\n",
    "                'tops': test_tuple[2],\n",
    "                'heights': test_tuple[3],\n",
    "                'widths': test_tuple[4],\n",
    "                'lefts': test_tuple[5]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            with open (struct + '.pickle', 'wb') as f:\n",
    "                pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "        except Exception as e:\n",
    "            print ('unable to save data', e)\n",
    "            \n",
    "    return struct + '.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already present, skipping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'svhn.pickle'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maybe_pickle('svhn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open ('svhn.pickle', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "except Exception as e:\n",
    "    print ('unable to process data', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image (image_file, path='train/', **box):\n",
    "    image_data = np.average(ndimage.imread(path+image_file), axis=2)\n",
    "    \n",
    "    if box['minTop'] <= 0: box['minTop'] = 0\n",
    "    if box['minLeft'] <= 0: box['minLeft'] = 0\n",
    "        \n",
    "    image_data = image_data[box['minTop']:box['maxTopHeight'], box['minLeft']:box['maxLeftWidth']]\n",
    "    image_data = imresize(image_data, (32,32))\n",
    "    image_data = (image_data.astype(float) - pixel_depth / 2) / pixel_depth\n",
    "    \n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_images (data, struct):\n",
    "    images = data[struct]['images']\n",
    "    tops = data[struct]['tops']\n",
    "    widths = data[struct]['widths']\n",
    "    heights = data[struct]['heights']\n",
    "    lefts = data[struct]['lefts']\n",
    "    \n",
    "    final_data = np.ndarray (shape = (images.shape[0], 32, 32), dtype=np.float32)\n",
    "    \n",
    "    for i in range (final_data.shape[0]):\n",
    "        if (i % 5000 == 0):\n",
    "            print (i, 'passed out of', final_data.shape[0], 'for:', struct)\n",
    "        try:\n",
    "            path = struct + '/'\n",
    "            charCount = data[struct]['labels'][i][data[struct]['labels'][i] > - 1].shape[0]\n",
    "            topHeights = np.array([tops[i][:charCount], heights[i][:charCount]])\n",
    "            leftWidths = np.array([lefts[i][:charCount], widths[i][:charCount]])\n",
    "            image = load_image (images[i], path, **{\n",
    "                    \"minTop\": min(topHeights[0,:]),\n",
    "                    \"minLeft\": min(leftWidths[0,:]),\n",
    "                    \"maxTopHeight\": topHeights.sum(axis=0).max(),\n",
    "                    \"maxLeftWidth\": leftWidths.sum(axis=0).max()\n",
    "                })\n",
    "            final_data[i,:,:] = image\n",
    "        except Exception as e:\n",
    "            img = np.average(ndimage.imread(path+images[i]), axis=2)\n",
    "            print (i, charCount, img.shape, {\n",
    "                    \"minTop\": min(topHeights[0,:]),\n",
    "                    \"minLeft\": min(leftWidths[0,:]),\n",
    "                    \"maxTopHeight\": topHeights.sum(axis=0).max(),\n",
    "                    \"maxLeftWidth\": leftWidths.sum(axis=0).max(),\n",
    "                    \"lefts\": lefts[i],\n",
    "                    \"widths\": widths[i],\n",
    "                    \"message\": e.message\n",
    "                })\n",
    "            return\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 passed out of 33402 for: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasilysh/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:7: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 passed out of 33402 for: train\n",
      "10000 passed out of 33402 for: train\n",
      "15000 passed out of 33402 for: train\n",
      "20000 passed out of 33402 for: train\n",
      "25000 passed out of 33402 for: train\n",
      "30000 passed out of 33402 for: train\n",
      "0 passed out of 13068 for: test\n",
      "5000 passed out of 13068 for: test\n",
      "10000 passed out of 13068 for: test\n"
     ]
    }
   ],
   "source": [
    "X_train = load_images(data, 'train')\n",
    "X_test = load_images(data, 'test')\n",
    "y_train = data['train']['labels']\n",
    "y_test = data['test']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open ('tensorflow_data.pickle', 'wb') as f:\n",
    "        pickle.dump({\n",
    "                'train': {'data': X_train, 'label': y_train},\n",
    "                'test': {'data': X_test, 'label': y_test}\n",
    "            }, f, pickle.HIGHEST_PROTOCOL)\n",
    "except Exception as e:\n",
    "    print ('unable to save data', struct, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
