{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize\n",
    "import string\n",
    "import h5py\n",
    "import matplotlib\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://ufldl.stanford.edu/housenumbers/'\n",
    "last_percent_reported = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "    global last_percent_reported\n",
    "    percent = int(count * blockSize * 100 / totalSize)\n",
    "    \n",
    "    if last_percent_reported != percent:\n",
    "        if percent % 5 == 0:\n",
    "            sys.stdout.write(\"%s%%\" % percent)\n",
    "            sys.stdout.flush()\n",
    "        else:\n",
    "            sys.stdout.write(\".\")\n",
    "            sys.stdout.flush()\n",
    "                \n",
    "        last_percent_reported = percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maybe_download(filename, expected_bytes, force=False):\n",
    "    if force or not os.path.exists(filename):\n",
    "        print('Attempting to download:', filename) \n",
    "        filename, _ = urlretrieve(url + filename, filename, reporthook=download_progress_hook)\n",
    "        print('\\nDownload Complete!')\n",
    "    statinfo = os.stat(filename)\n",
    "    if statinfo.st_size == expected_bytes:\n",
    "        print('Found and verified', filename)\n",
    "    else:\n",
    "        raise Exception(\n",
    "            'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "        return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified train.tar.gz\n",
      "Found and verified test.tar.gz\n"
     ]
    }
   ],
   "source": [
    "maybe_download('train.tar.gz', 404141560)\n",
    "maybe_download('test.tar.gz', 276555967)\n",
    "\n",
    "train_filename = 'train.tar.gz'\n",
    "test_filename = 'test.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maybe_extract(filename, force=False):\n",
    "    root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "    if os.path.isdir(root) and not force:\n",
    "        # You may override by setting force=True\n",
    "        print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "    else:\n",
    "        print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "        tar = tarfile.open(filename)\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "    data_folders = [\n",
    "        os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "        if os.path.isdir(os.path.join(root, d))]\n",
    "    return data_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train already present - Skipping extraction of train.tar.gz.\n",
      "test already present - Skipping extraction of test.tar.gz.\n"
     ]
    }
   ],
   "source": [
    "train_folders = maybe_extract(train_filename)\n",
    "test_folders = maybe_extract(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_attr (f, i, name):\n",
    "    attr = f[f['digitStruct']['bbox'][i][0]][name].value.squeeze()\n",
    "    \n",
    "    if attr.dtype == 'float64':\n",
    "        return attr.reshape(-1)\n",
    "    \n",
    "    return np.array([f[x].value for x in attr]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label (f, i):\n",
    "    label = f[f['digitStruct']['name'][i][0]].value.tostring()\n",
    "    return label.replace('\\x00', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data (path):\n",
    "    f = h5py.File(path)\n",
    "    \n",
    "    images = np.ndarray(shape = (f['digitStruct']['name'].shape[0],), dtype = '|S15')\n",
    "    labels = np.zeros((len(f['digitStruct']['bbox']), 6), dtype = 'float')\n",
    "    tops = np.zeros((len(f['digitStruct']['bbox']), 6), dtype = 'float')\n",
    "    heights = np.zeros((len(f['digitStruct']['bbox']), 6), dtype = 'float')\n",
    "    widths = np.zeros((len(f['digitStruct']['bbox']), 6), dtype = 'float')\n",
    "    lefts = np.zeros((len(f['digitStruct']['bbox']), 6), dtype = 'float')\n",
    "    labels.fill(10)\n",
    "    \n",
    "    for i in xrange(f['digitStruct']['name'].shape[0]):\n",
    "        images[i] = get_label(f, i)\n",
    "        \n",
    "        label_attr = get_attr(f, i, 'label')\n",
    "        top_attr = get_attr(f, i, 'top')\n",
    "        height_attr = get_attr(f, i , 'height')\n",
    "        width_attr = get_attr(f, i, 'width')\n",
    "        left_attr = get_attr(f, i , 'left')\n",
    "        \n",
    "        labels[i, :label_attr.shape[0]] = label_attr\n",
    "        tops[i, :top_attr.shape[0]] = top_attr\n",
    "        heights[i, :height_attr.shape[0]] = height_attr\n",
    "        widths[i, :width_attr.shape[0]] = width_attr\n",
    "        lefts[i, :left_attr.shape[0]] = left_attr\n",
    "        \n",
    "        if (i % 5000 == 0):\n",
    "            print (i, 'passed')\n",
    "        \n",
    "    return labels, images, tops, heights, widths, lefts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 passed\n",
      "5000 passed\n",
      "10000 passed\n",
      "15000 passed\n",
      "20000 passed\n",
      "25000 passed\n",
      "30000 passed\n",
      "0 passed\n",
      "5000 passed\n",
      "10000 passed\n"
     ]
    }
   ],
   "source": [
    "train_tuple = load_data('train/digitStruct.mat')\n",
    "test_tuple = load_data('test/digitStruct.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maybe_pickle (struct, force=False):\n",
    "    if os.path.exists(struct + '.pickle') and not force:\n",
    "        print('file already present, skipping')\n",
    "    else:\n",
    "        print('pickling file')\n",
    "        \n",
    "        dataset = {\n",
    "            'train': {\n",
    "                'labels': train_tuple[0],\n",
    "                'images': train_tuple[1],\n",
    "                'tops': train_tuple[2],\n",
    "                'heights': train_tuple[3],\n",
    "                'widths': train_tuple[4],\n",
    "                'lefts': train_tuple[5]\n",
    "            },\n",
    "            'test': {\n",
    "                'labels': test_tuple[0],\n",
    "                'images': test_tuple[1],\n",
    "                'tops': test_tuple[2],\n",
    "                'heights': test_tuple[3],\n",
    "                'widths': test_tuple[4],\n",
    "                'lefts': test_tuple[5]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            with open (struct + '.pickle', 'wb') as f:\n",
    "                pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "        except Exception as e:\n",
    "            print ('unable to save data', e)\n",
    "            \n",
    "    return struct + '.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickling file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'svhn.pickle'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maybe_pickle('svhn')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
